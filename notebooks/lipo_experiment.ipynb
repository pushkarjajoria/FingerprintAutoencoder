{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2434ce70-fba7-414a-babc-d6eff900dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Set the project root (adjust this path as needed)\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..')) if '__file__' in globals() else os.path.abspath(\"..\")\n",
    "sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d07f17b3-5f68-4459-8519-727422c76fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "from models.autoencoder import FingerprintAutoencoder\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from typing import Iterator, List, Tuple\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "import json\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d93e2d0-c6db-428c-abd4-9056981fd49d",
   "metadata": {},
   "source": [
    "### 2. Experiment Setup\n",
    "\n",
    "- **Feature types**:\n",
    "  1. molformer  \n",
    "  2. fingerprint  \n",
    "  3. compressed_fp_5  \n",
    "  4. compressed_fp_10  \n",
    "  5. molformer+fp  \n",
    "  6. molformer+compressed_fp_5  \n",
    "  7. molformer+compressed_fp_10  \n",
    "\n",
    "- **Prediction heads**:\n",
    "  1. mlp_1  \n",
    "  2. mlp_2  \n",
    "  3. mlp_3  \n",
    "  4. random_forest  \n",
    "\n",
    "- **CV**: 5-fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d89004c-3604-48e3-bea1-86079e12697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_EXTRACTORS = [\n",
    "    \"molformer\",\n",
    "    \"fingerprint\",\n",
    "    \"compressed_fp_5\",\n",
    "    \"compressed_fp_10\",\n",
    "    \"molformer+fp\",\n",
    "    \"molformer+compressed_fp_5\",\n",
    "    \"molformer+compressed_fp_10\"\n",
    "]\n",
    "\n",
    "PREDICTION_HEADS = [\"mlp_1\", \"mlp_2\", \"mlp_3\", \"random_forest\"]\n",
    "\n",
    "COMPRESSED_FP_PATHS = {\n",
    "    \"compressed_fp_5\": \"/data/users/pjajoria/model_checkpoints/autoencoder/compression_5\",\n",
    "    \"compressed_fp_10\": \"/data/users/pjajoria/model_checkpoints/autoencoder/compression_10\",\n",
    "    \"molformer+compressed_fp_5\": \"/data/users/pjajoria/model_checkpoints/autoencoder/compression_5\",\n",
    "    \"molformer+compressed_fp_10\": \"/data/users/pjajoria/model_checkpoints/autoencoder/compression_10\",\n",
    "}\n",
    "\n",
    "N_SPLITS = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4131b1-296b-4ae8-bcd6-96c6fc33e123",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45425fdc-9fce-4e7f-b7d5-8295e61edb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4200 molecules\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"/nethome/pjajoria/Github/thesis/data/processed/lipo.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Loaded {len(df)} molecules\")\n",
    "# df.head()\n",
    "# TODO: Scafold splitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9352a228-9323-4086-a519-f116ee565292",
   "metadata": {},
   "source": [
    "## Feature Extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79c03acf-c2de-4500-afec-665ec92e8324",
   "metadata": {},
   "outputs": [],
   "source": [
    "FPGEN = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=2048)\n",
    "def smis2torch_fp(smiles: List[str]):\n",
    "    # torch uses optimized dot products for float32 but not for int\n",
    "    # or bool\n",
    "    fps = np.zeros((len(smiles), 2048), dtype=np.float32)\n",
    "    for i, smi in enumerate(smiles):\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        fps[i, :] = FPGEN.GetFingerprintAsNumPy(mol)\n",
    "\n",
    "    return torch.from_numpy(fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bc5668b-f92a-4858-b5af-4ba6121c96a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3044860/2734702187.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "# All Models\n",
    "molformer = AutoModel.from_pretrained(\"ibm/MoLFormer-XL-both-10pct\", deterministic_eval=True, trust_remote_code=True).to(device)\n",
    "molformer_tokenizer = AutoTokenizer.from_pretrained(\"ibm/MoLFormer-XL-both-10pct\", trust_remote_code=True)\n",
    "\n",
    "\n",
    "def load_compressed_autoencoders():\n",
    "    input_dim = 2048\n",
    "    compression_levels = [5, 10]\n",
    "    base_path = \"/data/users/pjajoria/model_checkpoints/autoencoder/compression_{}\"\n",
    "\n",
    "    compressed_fps = {}\n",
    "    for comp in compression_levels:\n",
    "        latent_dim = int(input_dim * (comp / 100))\n",
    "        model = FingerprintAutoencoder(input_dim=input_dim, latent_dim=latent_dim)\n",
    "        ckpt_path = f\"{base_path.format(comp)}/ae_final.pth\"\n",
    "        model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        compressed_fps[str(comp)] = model\n",
    "\n",
    "    return compressed_fps\n",
    "\n",
    "compressed_fp_models = load_compressed_autoencoders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d90212b3-1927-4f45-a768-bd19aee877f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(smiles_list, feature_type):\n",
    "    \"\"\"\n",
    "    Returns np.ndarray of shape (N, D) for given smiles_list.\n",
    "    \"\"\"\n",
    "    if feature_type == \"molformer\":\n",
    "        # Load model directly\n",
    "        inputs = molformer_tokenizer(smiles_list, padding=True, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = molformer(**inputs)\n",
    "        return outputs.pooler_output\n",
    "    elif feature_type == \"fingerprint\":\n",
    "        return smis2torch_fp(smiles_list).to(device)\n",
    "\n",
    "    elif feature_type.startswith(\"compressed_fp\"):\n",
    "        compression = feature_type.split(\"_\")[-1]\n",
    "        return compressed_fp_models[compression].encoder(smis2torch_fp(smiles_list).to(device))\n",
    "    elif feature_type.startswith(\"molformer+\"):\n",
    "        # split e.g. \"molformer+compressed_fp_5\"\n",
    "        base, extra = feature_type.split(\"+\")\n",
    "        feat1 = extract_features(smiles_list, base)\n",
    "        feat2 = extract_features(smiles_list, extra)\n",
    "        return torch.concatenate([feat1, feat2], axis=1)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown feature type: {feature_type}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19844f0-9d77-441b-adad-8085a2547390",
   "metadata": {},
   "source": [
    "### Testing all the models forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62147226-1f9a-48d0-907b-b8d67711bae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3044860/2734702187.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "molformer: torch.Size([5, 768])\n",
      "fingerprint: torch.Size([5, 2048])\n",
      "compressed_fp_5: torch.Size([5, 102])\n",
      "compressed_fp_10: torch.Size([5, 204])\n",
      "molformer+fingerprint: torch.Size([5, 2816])\n",
      "molformer+compressed_fp_5: torch.Size([5, 870])\n",
      "molformer+compressed_fp_10: torch.Size([5, 972])\n"
     ]
    }
   ],
   "source": [
    "smiles_list = [\"CCO\", \"CC(=O)O\", \"c1ccccc1\", \"CCN(CC)CC\", \"C#N\"]\n",
    "\n",
    "compressed_fp_models = load_compressed_autoencoders()\n",
    "\n",
    "# Test each feature type\n",
    "feature_types = [\n",
    "    \"molformer\",\n",
    "    \"fingerprint\",\n",
    "    \"compressed_fp_5\",\n",
    "    \"compressed_fp_10\",\n",
    "    \"molformer+fingerprint\",\n",
    "    \"molformer+compressed_fp_5\",\n",
    "    \"molformer+compressed_fp_10\"\n",
    "]\n",
    "\n",
    "# Test and print output shapes\n",
    "for ft in feature_types:\n",
    "    try:\n",
    "        features = extract_features(smiles_list, ft)\n",
    "        print(f\"{ft}: {features.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{ft}: Failed with error -> {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fce7b73-fd31-4c37-9274-80784b55a0db",
   "metadata": {},
   "source": [
    "## Prediction Heads\n",
    "\n",
    "- **MLP**: 1-, 2-, or 3-layer feedforward\n",
    "- **RF**: scikit-learn RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53a46c88-c486-404f-a524-8c663092d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        dims = [input_dim] + hidden_dims + [1]\n",
    "        for i in range(len(dims)-2):\n",
    "            layers.append(nn.Linear(dims[i], dims[i+1]))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(dims[-2], dims[-1]))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def get_model(model_type, input_dim):\n",
    "    if model_type == \"mlp_1\":\n",
    "        return MLP(input_dim, [128])\n",
    "    if model_type == \"mlp_2\":\n",
    "        return MLP(input_dim, [256, 128])\n",
    "    if model_type == \"mlp_3\":\n",
    "        return MLP(input_dim, [512, 256, 128])\n",
    "    if model_type == \"random_forest\":\n",
    "        return RandomForestRegressor(n_estimators=100, random_state=SEED)\n",
    "    raise ValueError(model_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4084f6aa-c9b0-4629-92b1-08200b3349ec",
   "metadata": {},
   "source": [
    "## Run k-Fold CV & Collect Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e83b365-ef50-4b1c-8f84-fa1f4a43a755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa988d47d8ba44f6bf7e1e419ed48c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Feature+Head combos:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm  # for notebook-friendly progress bars\n",
    "\n",
    "results = []\n",
    "\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Outer progress bar for total number of (feat x head) runs\n",
    "total_runs = len(FEATURE_EXTRACTORS) * len(PREDICTION_HEADS)\n",
    "outer_pbar = tqdm(total=total_runs, desc=\"Feature+Head combos\")\n",
    "\n",
    "for feat in FEATURE_EXTRACTORS:\n",
    "    X = extract_features(df[\"smiles\"].tolist(), feat)  # (N, D)\n",
    "    y = df[\"target\"].values\n",
    "\n",
    "    for head in PREDICTION_HEADS:\n",
    "        fold_metrics = []\n",
    "\n",
    "        # Optional: progress bar for folds if folds are large\n",
    "        # fold_pbar = tqdm(total=N_SPLITS, desc=f\"Fold ({feat}, {head})\")\n",
    "\n",
    "        for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "            X_tr, y_tr = X[train_idx], y[train_idx]\n",
    "            X_te, y_te = X[test_idx], y[test_idx]\n",
    "\n",
    "            model = get_model(head, input_dim=X.shape[1])\n",
    "\n",
    "            if head.startswith(\"mlp\"):\n",
    "                EPOCHS = 20\n",
    "                BATCH_SIZE = 64\n",
    "                LR = 1e-3\n",
    "\n",
    "                model = model.to(device)\n",
    "                model.train()\n",
    "\n",
    "                ds = TensorDataset(torch.from_numpy(X_tr).float(), torch.from_numpy(y_tr).float().unsqueeze(1))\n",
    "                loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "                criterion = nn.MSELoss()\n",
    "\n",
    "                # Epoch progress bar\n",
    "                epoch_pbar = tqdm(range(EPOCHS), desc=f\"Training {feat}+{head} fold {fold+1}\", leave=False)\n",
    "\n",
    "                for epoch in epoch_pbar:\n",
    "                    running_loss = 0.0\n",
    "                    for xb, yb in loader:\n",
    "                        xb, yb = xb.to(device), yb.to(device)\n",
    "                        optimizer.zero_grad()\n",
    "                        preds = model(xb)\n",
    "                        loss = criterion(preds, yb)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        running_loss += loss.item()\n",
    "\n",
    "                    avg_loss = running_loss / len(loader)\n",
    "                    epoch_pbar.set_postfix(loss=f\"{avg_loss:.4f}\")\n",
    "\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    preds = model(torch.from_numpy(X_te).float().to(device)).cpu().numpy().squeeze()\n",
    "            else:\n",
    "                model.fit(X_tr, y_tr)\n",
    "                preds = model.predict(X_te)\n",
    "\n",
    "            rmse = mean_squared_error(y_te, preds, squared=False)\n",
    "            r2   = r2_score(y_te, preds)\n",
    "            mae  = mean_absolute_error(y_te, preds)\n",
    "\n",
    "            fold_metrics.append({\n",
    "                \"rmse\": rmse,\n",
    "                \"r2\":   r2,\n",
    "                \"mae\":  mae\n",
    "            })\n",
    "\n",
    "            # fold_pbar.update(1)\n",
    "\n",
    "        # fold_pbar.close()\n",
    "\n",
    "        rmse_vals = [m[\"rmse\"] for m in fold_metrics]\n",
    "        r2_vals   = [m[\"r2\"]   for m in fold_metrics]\n",
    "        mae_vals  = [m[\"mae\"]  for m in fold_metrics]\n",
    "\n",
    "        result_entry = {\n",
    "            \"feature\": feat,\n",
    "            \"head\":    head,\n",
    "            \"rmse_mean\": np.mean(rmse_vals),\n",
    "            \"rmse_std\":  np.std(rmse_vals),\n",
    "            \"r2_mean\":   np.mean(r2_vals),\n",
    "            \"r2_std\":    np.std(r2_vals),\n",
    "            \"mae_mean\":  np.mean(mae_vals),\n",
    "            \"mae_std\":   np.std(mae_vals),\n",
    "        }\n",
    "        results.append(result_entry)\n",
    "\n",
    "        print(f\"{feat} + {head}:  \"\n",
    "              f\"RMSE {result_entry['rmse_mean']:.3f}±{result_entry['rmse_std']:.3f},  \"\n",
    "              f\"R² {result_entry['r2_mean']:.3f}±{result_entry['r2_std']:.3f},  \"\n",
    "              f\"MAE {result_entry['mae_mean']:.3f}±{result_entry['mae_std']:.3f}\")\n",
    "\n",
    "        outer_pbar.update(1)\n",
    "\n",
    "outer_pbar.close()\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "with open(output_dir / \"results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b4a003-d444-4b6d-8feb-1fd863b122d4",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7900a2-a0fc-41c7-93e5-91dbd1afb4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppose your `results` list contains one entry per fold:\n",
    "# [\n",
    "#   {\"feature\": ..., \"head\": ..., \"r2\": 0.75, \"mae\": 0.45},\n",
    "#   ...\n",
    "# ]\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# 1. Melt into “long” form so we can Facet by metric\n",
    "df_long = df.melt(\n",
    "    id_vars=[\"feature\", \"head\"],\n",
    "    value_vars=[\"r2\", \"mae\"],\n",
    "    var_name=\"metric\",\n",
    "    value_name=\"value\"\n",
    ")\n",
    "\n",
    "# 2. Set up one subplot per head\n",
    "heads = df_long[\"head\"].unique()\n",
    "n_heads = len(heads)\n",
    "fig, axes = plt.subplots(1, n_heads, figsize=(4*n_heads, 6), sharey=False)\n",
    "\n",
    "for ax, head in zip(axes, heads):\n",
    "    sub = df_long[df_long[\"head\"] == head]\n",
    "    # 3. Draw a boxplot of value by feature, with hue=metric\n",
    "    #    (so R2 and MAE appear next to each other for each feature)\n",
    "    pd.plotting.boxplot(\n",
    "        sub, \n",
    "        by=[\"feature\", \"metric\"], \n",
    "        column=\"value\",\n",
    "        ax=ax,\n",
    "        rot=45,\n",
    "        grid=False,\n",
    "        showmeans=True\n",
    "    )\n",
    "    ax.set_title(head)\n",
    "    ax.get_figure().suptitle(\"\")  # remove default “Boxplot grouped by ...” title\n",
    "    ax.set_xlabel(\"Feature extractor\")\n",
    "    ax.set_ylabel(\"Score\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71322dae-949b-4454-95d1-2012bbac740c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
